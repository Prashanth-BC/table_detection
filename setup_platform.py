#!/usr/bin/env python3
"""
Universal platform setup script for table detection training.
Automatically detects and configures for Google Colab, Kaggle, or local environments.
"""

import os
import sys
from pathlib import Path
from scripts.platform_detector import get_platform_config

def setup_platform():
    """Setup platform-specific environment for table detection training"""

    print("üîß Table Detection Platform Setup")
    print("=" * 50)

    # Get platform configuration
    platform_config = get_platform_config()

    # Display platform information
    platform_config.print_platform_info()

    # Setup directories
    print("\nüìÅ Setting up directories...")
    platform_config.setup_directories()

    # Platform-specific optimizations
    print(f"\n‚öôÔ∏è Applying {platform_config.platform.upper()} optimizations...")

    if platform_config.platform == 'kaggle':
        setup_kaggle_optimizations(platform_config)
    elif platform_config.platform == 'colab':
        setup_colab_optimizations(platform_config)
    else:
        setup_local_optimizations(platform_config)

    # Display training recommendations
    print_training_recommendations(platform_config)

    return platform_config

def setup_kaggle_optimizations(config):
    """Apply Kaggle-specific optimizations"""

    # Create additional symlinks for convenience
    symlinks = [
        ("/kaggle/working/data", "/kaggle/tmp/data"),
        ("/kaggle/working/models", "/kaggle/tmp/models")
    ]

    for link_path, target_path in symlinks:
        link = Path(link_path)
        if not link.exists() and Path(target_path).exists():
            link.symlink_to(target_path)
            print(f"‚úì Created symlink: {link_path} -> {target_path}")

    # Set environment variables for optimal performance
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Better error reporting
    os.environ['TORCH_HOME'] = '/kaggle/tmp/.torch'  # Cache torch models

    print("‚úì Kaggle optimizations applied:")
    print("  ‚Ä¢ Symlinks created for easy data access")
    print("  ‚Ä¢ CUDA debugging enabled")
    print("  ‚Ä¢ Torch cache redirected to /kaggle/tmp/")

def setup_colab_optimizations(config):
    """Apply Google Colab-specific optimizations"""

    # Check if GPU is available
    try:
        import torch
        if torch.cuda.is_available():
            print(f"‚úì GPU detected: {torch.cuda.get_device_name(0)}")
        else:
            print("‚ö†Ô∏è No GPU detected. Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU")
    except ImportError:
        print("‚ö†Ô∏è PyTorch not installed")

    # Set environment variables
    os.environ['TORCH_HOME'] = '/content/.torch'  # Cache torch models

    print("‚úì Colab optimizations applied:")
    print("  ‚Ä¢ Torch cache configured")
    print("  ‚Ä¢ GPU status checked")

def setup_local_optimizations(config):
    """Apply local environment optimizations"""

    print("‚úì Local environment detected:")
    print("  ‚Ä¢ Using relative paths for data")
    print("  ‚Ä¢ Full hardware access available")
    print("  ‚Ä¢ No time or storage limitations")

def print_training_recommendations(config):
    """Print platform-specific training recommendations"""

    print(f"\nüéØ {config.platform.upper()} Training Recommendations:")
    print("=" * 50)

    if config.platform == 'kaggle':
        print("üî• KAGGLE TIPS:")
        print("‚Ä¢ Use 30-hour GPU quota efficiently")
        print("‚Ä¢ Save checkpoints frequently (every 5 epochs)")
        print("‚Ä¢ Upload large datasets as Kaggle datasets")
        print("‚Ä¢ Use /kaggle/tmp/ for temporary large files")
        print("‚Ä¢ Save final models in /kaggle/working/ for download")
        print("‚Ä¢ Consider using Kaggle's built-in datasets")

    elif config.platform == 'colab':
        print("üî• COLAB TIPS:")
        print("‚Ä¢ 12-hour session limit - save work frequently")
        print("‚Ä¢ Use Google Drive for persistent storage")
        print("‚Ä¢ Enable GPU: Runtime ‚Üí Change runtime type ‚Üí GPU")
        print("‚Ä¢ Download models before session expires")
        print("‚Ä¢ Use smaller batch sizes if memory limited")
        print("‚Ä¢ Mount Google Drive: files.upload() for data")

    else:
        print("üî• LOCAL TIPS:")
        print("‚Ä¢ Full control over hardware and time")
        print("‚Ä¢ Use larger batch sizes if GPU memory allows")
        print("‚Ä¢ Enable distributed training for multiple GPUs")
        print("‚Ä¢ Use full datasets for best results")
        print("‚Ä¢ Consider using Docker for reproducibility")

    print(f"\nüìä Quick Start Commands:")
    print(f"1. Setup data: python scripts/data_converter.py")
    print(f"2. Start training: python train_table_detection.py")
    print(f"3. Check results: ls {config.config['results_dir']}/")

def verify_setup(config):
    """Verify that setup was successful"""

    print(f"\nüîç Verifying setup...")

    # Check critical directories
    critical_dirs = [
        config.config['data_root'],
        config.config['checkpoints_dir'],
        config.config['logs_dir'],
        config.config['results_dir']
    ]

    missing_dirs = []
    for dir_path in critical_dirs:
        if not Path(dir_path).exists():
            missing_dirs.append(dir_path)
        else:
            print(f"‚úì {dir_path}")

    if missing_dirs:
        print(f"‚ùå Missing directories: {missing_dirs}")
        return False

    print("‚úÖ All directories verified!")
    return True

def main():
    """Main setup function"""

    try:
        # Setup platform
        config = setup_platform()

        # Verify setup
        if verify_setup(config):
            print(f"\nüéâ {config.platform.upper()} setup completed successfully!")
            print("You're ready to start table detection training!")
        else:
            print(f"\n‚ùå Setup verification failed!")
            return False

        return True

    except Exception as e:
        print(f"\n‚ùå Setup failed: {e}")
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)